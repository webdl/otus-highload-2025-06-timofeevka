# Репликация и нагрузочное тестирование

## Оглавление

- [Подготовка](#подготовка)
    - [Перевод аутентификации на JWT](#перевод-аутентификации-на-jwt)
    - [Докеризация приложения и мониторинг](#докеризация-приложения-и-мониторинг)
    - [Кластеризация PostgreSQL](#кластеризация-postgresql)
- [Нагрузочное тестирование. Этап №1](#нагрузочное-тестирование-этап-1)
- [Добавление в проект Dynamic datasource](#добавление-в-проект-dynamic-datasource)
- [Нагрузочное тестирование. Этап №2](#нагрузочное-тестирование-этап-2)
- [Настройка синхронной репликации](#настройка-синхронной-репликации)
    - [Про синхронную репликацию](#про-синхронную-репликацию)
- [Нагрузочное тестирование. Этап №3](#нагрузочное-тестирование-этап-3)
    - [Проверка потерянных данных](#проверка-потерянных-данных)

## Подготовка

Для выполнения ДЗ была проведена предварительная подготовка окружения, которая позволяет снимать метрики. Вот из чего она состояла:

### Перевод аутентификации на JWT

Ранее в системе использовалась Basic Auth, из-за чего приходилось проходить авторизацию при каждом запросе. Это негативно влиялo на
показатели задержки и пропускной способности, так как, например, из примерно 100 мс на запрос данных о пользователе около 70 мс уходило
на проверку прав. Это удалось выявить с помощью
[MethodExecutionTimeLoggerAspect.java](../user-service/src/main/java/ru/webdl/otus/socialnetwork/MethodExecutionTimeLoggerAspect.java) и более детальных
измерений производительности на каждом этапе авторизации.

Поэтому решил перейти на JWT, чтобы после единой авторизации использовать легковесную аутентификацию по токену. Это значительно сократило
время обработки запросов — например, запрос данных о пользователе с уже полученным токеном занимает около 10 мс.

Однако нагрузочное тестирование не использует заранее подготовленный токен, а получает его в процессе, поэтому пришлось оптимизировать и
этап авторизации. При комплексном тестировании (авторизация + другие API) выяснилось, что получение токена занимает около 100 мс, что
негативно влияет на показатели задержки и пропускной способности для последующих вызовов.

Для решения этой проблемы в файле
[PasswordEncoderConfiguration.java](../user-service/src/main/java/ru/webdl/otus/socialnetwork/infra/conf/PasswordEncoderConfiguration.java) была
добавлена настройка, которая в dev-окружении использует минимальную сложность шифрования. После этого авторизация через API стала
занимать около 15 мс — что уже приемлемо по сравнению с другими запросами API.

### Докеризация приложения и мониторинг

Следующий шаг к упрощению локального развертывания не только приложения, но и сопутствующих систем. Так, в файле
[docker-compose.yml](../docker-compose-infra.yml), вы увидите следующие системы:

- **prometheus** (+[конфигурация](../deploy/prometheus/config/prometheus.yml)) — для сбора метрик с остальных систем
- **grafana** (+[дашборды](../deploy/grafana/dashboards)) — для отображения графиков по метрикам
- **cadvisor** — для мониторинга docker-контейнеров
- **node-exporter** — для мониторинга операционной системы (ставится в т.ч. на сервера с БД)
- **postgres-exporter** — для мониторинга кластера PostgreSQL

Все приложения поднимаются автоматически с помощью docker-compose и взаимодействуют друг с другом.

### Кластеризация PostgreSQL

У меня уже было поднято несколько виртуальных машин с PostgreSQL 16, развертывание которых подробно описано в
[другой моей работе](https://github.com/webdl/otus-PostgreSQL-2025-05-timofeevka/tree/main/deploy/vm), поэтому я не стал докеризовать их.
И поэтому ниже описаны только шаги, с помощью которых я производил настройку кластеризации.

Итак, все есть 3 машины: `pg-master`, `pg-slave01`, `pg-slave02`.

На `pg-master` мы создает УЗ для репликации:

```sql
CREATE ROLE replica_user WITH
    LOGIN
    REPLICATION
    PASSWORD 'replica_user';
```

и настраиваем файл `pg_hba.conf`:

```yaml
{ type: host, database: replication, user: replica_user, address: '10.0.2.0/24', auth_method: md5 }
```

Это обязательное условие для физической репликации.

Далее на `pg-slave01` и `pg-slave02` выполняем одинаковые действия ниже. Для начала остановим кластер и изменим конфигурацию:

```shell
sudo su postgres
pg_ctlcluster 16 main stop
```

в файле `postgresql.conf`:

```
primary_conninfo='host=10.0.2.2 port=5432 user=replica_user password=replica_user application_name=slave01'
```

далее удаляет или бекапим и переносим текущий каталог с данными:

```shell
rm -rf /mnt/pg_data/main/
```

и скачиваем данные с `pg-master` (требуется пароль от `replica_user`):

```shell
pg_basebackup -h 10.0.2.2 -D /mnt/pg_data/main/ -U replica_user -P --wal-method=stream -R
```

Запускаем кластер и через логи смотрим, что всё хорошо:

```shell
pg_ctlcluster 16 main start
```

Повторияем на второй ВМ.

Делаем простую проверку, например:

1. Подключитесь к `pg-master` с помощью PgAdmin4 и сделайте изменения в данных;
2. Подключитесь к `pg-slave01` и `pg-slave02` и проверьте, что данные изменились.

## Нагрузочное тестирование. Этап №1

Файл [hw03.jmx](/user-service/src/test/jmeter/hw03.jmx) содержит два профиля:

- **Get profile & Find users** — получает токен после авторизации, запрашивает пользователя с рандомным ID и ищет пользователей с
  рандомными ФИ.
- **Register users** — регистрирует пользователя с рандомными данными.

Выполняем трех-минутную нагрузку в 100 пользователей (потоков) и профилем **Get profile & Find users** и смотрим на полученные результаты:

### JMeter

| Label          | # Samples | Average | Median | 90% Line | 95% Line | 99% Line | Min | Max | Error % | Throughput | Received KB/sec | Sent KB/sec |
|----------------|-----------|---------|--------|----------|----------|----------|-----|-----|---------|------------|-----------------|-------------|
| /login         | 201276    | 20      | 18     | 36       | 46       | 64       | 1   | 161 | 0.000%  | 1117.88948 | 885.04          | 332.97      |
| /user/get/<id> | 201254    | 32      | 31     | 57       | 67       | 90       | 1   | 198 | 0.000%  | 1117.76108 | 653.03          | 439.77      |
| /user/find     | 201216    | 34      | 33     | 60       | 70       | 93       | 1   | 207 | 0.000%  | 1117.48176 | 22696.80        | 475.80      |
| TOTAL          | 603746    | 29      | 25     | 53       | 64       | 86       | 1   | 207 | 0.000%  | 3352.65438 | 24232.35        | 1248.36     |

**Latency:**

![get-profile-one-pg-latency.png](img/hw03/get-profile-one-pg-latency.png)

**Throughput:**

![get-profile-one-pg-throughput.png](img/hw03/get-profile-one-pg-throughput.png)

### Grafana

**Приложение (docker):**

![get-profile-one-pg-app.jpg](img/hw03/get-profile-one-pg-app.jpg)

**БД (pg-master):**

![get-profile-one-pg-pg_master.jpg](img/hw03/get-profile-one-pg-pg_master.jpg)

## Добавление в проект Dynamic datasource

Для реализации Dynamic datasource добавляем зависимость:

```
...
<dependency>
    <groupId>com.baomidou</groupId>
    <artifactId>dynamic-datasource-spring-boot3-starter</artifactId>
    <version>4.3.1</version>
</dependency>
...
```

В классе [UserRepositoryImpl.java](../user-service/src/main/java/ru/webdl/otus/socialnetwork/infra/user/entities/UserRepositoryImpl.java) добавляем
аннотацию `@DS("slave_1")` на методы `findById` и `findByUsername`, а `@DS("slave_2")` на метод `findByFirstLastName`. Таким образом мы
распределим нагрузку на чтение на две ноды.

## Нагрузочное тестирование. Этап №2

Запускаем нагрузочное тестирование и смотрим результаты. Забегая вперед видим, что latency снизилось на ~10%, а throughput вырос на ~20%.

### JMeter

| Label          | # Samples | Average | Median | 90% Line | 95% Line | 99% Line | Min | Max | Error % | Throughput | Received KB/sec | Sent KB/sec |
|----------------|-----------|---------|--------|----------|----------|----------|-----|-----|---------|------------|-----------------|-------------|
| /login         | 244803    | 21      | 19     | 44       | 54       | 77       | 2   | 228 | 0.000%  | 1359.64654 | 1076.44         | 404.97      |
| /user/get/<id> | 244765    | 30      | 29     | 53       | 63       | 85       | 2   | 224 | 0.000%  | 1359.57896 | 794.31          | 534.90      |
| /user/find     | 244716    | 19      | 17     | 34       | 41       | 60       | 2   | 268 | 0.000%  | 1359.29923 | 27211.00        | 578.76      |
| TOTAL          | 734284    | 24      | 21     | 45       | 55       | 78       | 2   | 268 | 0.000%  | 4078.24537 | 29078.95        | 1518.53     |

**Latency:**

![get-profile-three-pg-latency.png](img/hw03/get-profile-three-pg-latency.png)

**Throughput:**

![get-profile-three-pg-throughput.png](img/hw03/get-profile-three-pg-throughput.png)

### Grafana

**Приложение (docker):**

![get-profile-three-pg-app.jpg](img/hw03/get-profile-three-pg-app.jpg)

**БД (pg-master):**

![get-profile-three-pg-pg_master.jpg](img/hw03/get-profile-three-pg-pg_master.jpg)

**БД (pg-slave-1):**

![get-profile-three-pg-pg_slave_1.jpg](img/hw03/get-profile-three-pg-pg_slave_1.jpg)

**БД (pg-slave-2):**

![get-profile-three-pg-pg_slave_2.jpg](img/hw03/get-profile-three-pg-pg_slave_2.jpg)

## Настройка синхронной репликации

В файле `postgresql.conf` на сервере `pg-master` задаем:

```
synchronous_commit = on # для явного указания уровня
synchronous_standby_names = 'slave01, slave02'
wal_sender_timeout = 15s # по-умолчанию 60 секунд
```

Что говорит нам:

- Ожидает подтверждение от `slave01` (если он доступен)
- Если `slave01` недоступен → ожидает `slave02`

Перезагружаем сервер `pg-master`.

Создаем представление для удобного отслеживания репликаций:

```sql
CREATE VIEW replication_status AS
SELECT application_name,
       client_addr,
       state,
       sync_state,
       write_lag,
       flush_lag,
       replay_lag
FROM pg_stat_replication;
```

Проверяем:

```
select * from pg_stat_replication;

-[ RECORD 1 ]----+------------------------------
pid              | 52912
usesysid         | 84861
usename          | replica_user
application_name | slave02
client_addr      | 10.0.2.4
client_hostname  | 
client_port      | 59546
backend_start    | 2025-09-19 09:11:03.270324+00
backend_xmin     | 
state            | streaming
sent_lsn         | 41/D3E000F0
write_lsn        | 41/D3E000F0
flush_lsn        | 41/D3E000F0
replay_lsn       | 41/D3E000F0
write_lag        | 
flush_lag        | 
replay_lag       | 
sync_priority    | 2
sync_state       | potential
reply_time       | 2025-09-19 09:11:49.536309+00
-[ RECORD 2 ]----+------------------------------
pid              | 52913
usesysid         | 84861
usename          | replica_user
application_name | slave01
client_addr      | 10.0.2.3
client_hostname  | 
client_port      | 35032
backend_start    | 2025-09-19 09:11:03.283435+00
backend_xmin     | 
state            | streaming
sent_lsn         | 41/D3E000F0
write_lsn        | 41/D3E000F0
flush_lsn        | 41/D3E000F0
replay_lsn       | 41/D3E000F0
write_lag        | 
flush_lag        | 
replay_lag       | 
sync_priority    | 1
sync_state       | sync
reply_time       | 2025-09-19 09:11:49.52715+00
```

Атрибут `sync_state` показывет режимы репликации для каждого сервера.

### Про синхронную репликацию

Синхронная репликация снижает производительность всех UPDATE/INSERT/DELETE запросов на 10-40% в зависимости от скорости сети. Ее
рекомендуют использовать только для финансовых операций, где несогласованность данных недопустима. В системах же более низкого класса,
таких как социальные сети, производительность выходит на первый план и используется модель **Eventual Consistency** (Согласованность в 
конечном счёте).

Эта модель подразумевает, что клиент БД (наше приложение) знает о понятии Replication lag и его код написат с учетом возможных проблем. Так,
например, в файле [UserRepositoryImpl.java](../user-service/src/main/java/ru/webdl/otus/socialnetwork/infra/user/entities/UserRepositoryImpl.java)
фукция `create` в SQL-запросе имеет строку `RETURNING`, которая сразу поле создания новой записи возвращает сгенерированное значение 
`user_id`. А это избавляет нас от усложненной логики получения пользователя через функцию `findByUsername`, которая, в свою очередь, имеет
аннотацию `@DS("slave_1")` и могла бы вызвать проблему Replication lag.

Таким образом мы гарантируем, что сможем получить данные после их вставки. Этот паттерн называется **Read-after-write**.
Он не является единственным подходом к реализации **Eventual Consistency**, но самый простой в понимании.

Еще один нюанса настройки синхронной репликации заключается в том, что по-умолчанию в PostgreSQL установлен уровень `on` в
параметре `synchronous_commit`, но он работает как `local`, если параметр `synchronous_standby_names` не задан. В параметре
`synchronous_standby_names` должны быть перечислены `application_name` каждого slave-сервера, который мы указывали при настройке реплики
в разделе [Кластеризация PostgreSQL](#кластеризация-postgresql).

Таблица сравнения разных уровней синхронизации:

| Уровень      | Потеря данных       | Производительность | Использование              |
|--------------|---------------------|--------------------|----------------------------|
| off          | Высокий риск        | ⚡️⚡️⚡️⚡️⚡️         | Аналитика, логи            |
| local        | Нет (только master) | ⚡️⚡️⚡️⚡️           | Сессии, кэш                |
| remote_write | Средний риск        | ⚡️⚡️⚡              | Баланс надежности/скорости |
| on           | Минимальный риск    | ⚡️⚡️               | Финансовые операции        |
| remote_apply | Практически нет     | ⚡️                 | Immediate consistency      |

## Нагрузочное тестирование. Этап №3

Тестирование проводится по следующим параметрам:

- 90 потоков читают данные по профилю **Get profile & Find users**
- 10 потоков регистрируют новых пользователей по профилю **Register users**
- После 2.5 минуты вырубаем `pg-master` через `kill -9`

### JMeter

**Get profile & Find users**

| Label          | # Samples | Average | Median | 90% Line | 95% Line | 99% Line | Min | Max   | Error % | Throughput | Received KB/sec | Sent KB/sec |
|----------------|-----------|---------|--------|----------|----------|----------|-----|-------|---------|------------|-----------------|-------------|
| /login         | 164311    | 7       | 6      | 13       | 16       | 24       | 2   | 76    | 0.000%  | 961.69289  | 761.38          | 286.44      |
| /user/get/<id> | 164311    | 58      | 30     | 59       | 69       | 100      | 1   | 60113 | 0.047%  | 711.56794  | 415.83          | 279.96      |
| /user/find     | 164233    | 58      | 43     | 108      | 128      | 178      | 3   | 60082 | 0.007%  | 711.52288  | 14967.29        | 302.95      |
| TOTAL          | 492855    | 41      | 19     | 71       | 97       | 142      | 1   | 60113 | 0.018%  | 2134.26437 | 15939.56        | 794.69      |

![test3-get-profile-throughput.png](img/hw03/test3-get-profile-throughput.png)

**Register users**

| Label          | # Samples | Average | Median | 90% Line | 95% Line | 99% Line | Min | Max   | Error % | Throughput | Received KB/sec | Sent KB/sec |
|----------------|-----------|---------|--------|----------|----------|----------|-----|-------|---------|------------|-----------------|-------------|
| /user/register | 69681     | 28      | 15     | 48       | 63       | 92       | 3   | 30027 | 0.377%  | 346.97546  | 210.96          | 174.93      |

![test3-register-user-throughput.png](img/hw03/test3-register-user-throughput.png)

### Проверка потерянных данных

Последний успешный запрос на создание УЗ из JMeter содержал данные:

```json
{
  "firstName": "Еермал",
  "lastName": "Друлиг",
  "birthDate": "2011-06-28",
  "gender": "m",
  "interests": "Жллкапмтудитбгус",
  "cityId": 69,
  "username": "user_4530843",
  "password": "password"
}
```

и получил ответ:

```json
{
  "id": 2773785,
  "firstName": "Еермал",
  "lastName": "Друлиг",
  "birthDate": "2011-06-28",
  "gender": "m",
  "interests": "Жллкапмтудитбгус",
  "cityId": 69,
  "username": "user_4530843"
}
```

Первый **неуспешный** запрос, который пришелся на момент отключения `pg-master`:

```json
{
  "firstName": "Кмсджг",
  "lastName": "Пбвзтн",
  "birthDate": "2015-03-02",
  "gender": "m",
  "interests": "Гилславибкгмрбиб",
  "cityId": 53,
  "username": "user_9264952",
  "password": "password"
}
```

получил ответ:

```json
{
  "message": "Hibernate transaction: Unable to commit against JDBC Connection; An I/O error occurred while sending to the backend.",
  "code": 1,
  "status": "INTERNAL_SERVER_ERROR",
  "timestamp": 1758273856156
}
```

Пока выключен `pg-master` подключимся на `pg-slave01` и `pg-slave02` и сделаем выборку по последним записям в
таблице `users` с ID чуть меньшим, чем удалось получить в последнем успешном запросе. Оба сервера вернули один и тот же результат:

```sql
select user_id, username from users where user_id >= 2773780;

user_id |   username   
---------+--------------
 2773780 | user_5290802
 2773781 | user_3240022
 2773782 | user_4085763
 2773783 | user_4376007
 2773784 | user_2188319
 2773785 | user_4530843
 2773786 | user_122004
 2773787 | user_6810711
 2773788 | user_9264952
(9 rows)
```

Видим даже, что последняя запись совпадает с **Первым неуспешный запросом** из JMeter.

Теперь выключаем оба сервера и включаем `pg-master`, чтобы они не начали синхронизироваться между друг другом. Для начала смотрим логи
запуска:

```
2025-09-19 09:31:37.215 UTC [53149] LOG:  database system was interrupted; last known up at 2025-09-19 09:23:53 UTC
2025-09-19 09:31:37.238 UTC [53150] socialnet@socialnet FATAL:  the database system is starting up
2025-09-19 09:31:37.399 UTC [53149] LOG:  database system was not properly shut down; automatic recovery in progress
2025-09-19 09:31:37.401 UTC [53149] LOG:  redo starts at 41/D98D3678
2025-09-19 09:31:37.487 UTC [53149] LOG:  invalid record length at 41/DCCA8F38: expected at least 24, got 0
2025-09-19 09:31:37.487 UTC [53149] LOG:  redo done at 41/DCCA8F08 system usage: CPU: user: 0.06 s, system: 0.01 s, elapsed: 0.08 s
2025-09-19 09:31:37.491 UTC [53147] LOG:  checkpoint starting: end-of-recovery immediate wait
2025-09-19 09:31:37.621 UTC [53147] LOG:  checkpoint complete: wrote 9114 buffers (7.0%); 0 WAL file(s) added, 0 removed, 3 recycled; write=0.091 s, sync=0.035 s, total=0.130 s; sync files=11, longest=0.034 s, average=0.004 s; distance=53078 kB, estimate=53078 kB; lsn=41/DCCA8F38, redo lsn=41/DCCA8F38
2025-09-19 09:31:37.623 UTC [53145] LOG:  database system is ready to accept connections
```

```
2025-09-19 09:31:37.399 UTC [53149] LOG: database system was not properly shut down; automatic recovery in progress
2025-09-19 09:31:37.401 UTC [53149] LOG: redo starts at 41/D98D3678
```

Говорит о том, система не была завершена корректно и начался процесс восстановления. PostgreSQL использует WAL запись с номером 41/D98D3678
для воспроизведения всех завершенных транзакций, которые не были применены к файлам данных до сбоя.

```
2025-09-19 09:31:37.487 UTC [53149] LOG: invalid record length at 41/DCCA8F38: expected at least 24, got 0
2025-09-19 09:31:37.487 UTC [53149] LOG: redo done at 41/DCCA8F08 system usage: CPU: user: 0.06 s, system: 0.01 s, elapsed: 0.08 s
```

Это не ошибка, а нормальная часть процесса восстановления! PostgreSQL читает WAL-логи до конца, но последняя запись в логе часто бывает
неполной (так как она могла записываться в момент сбоя). Система ожидала как минимум 24 байта данных, но вместо этого достигла конца
файла (получила 0 байт). Это сигнал для БД, что восстановление нужно завершить на предыдущей валидной записи.

Восстановление успешно завершено до номера 41/DCCA8F08. Все данные, которые должны были быть сохранены, были восстановлены. Процесс занял
0.08 секунды.

```
2025-09-19 09:31:37.491 UTC [53147] LOG: checkpoint starting: end-of-recovery immediate wait
2025-09-19 09:31:37.621 UTC [53147] LOG: checkpoint complete: ...
```

После восстановления немедленно запускается контрольная точка (checkpoint). Ее задача — записать все данные, которые были
применены в память во время recovery, на физический диск, чтобы гарантировать целостность и обеспечить нормальную работу с этого момента.

Контрольная точка успешно завершена. Подробная статистика (сколько буферов записано, сколько времени заняло и т.д.)
показывает, что процесс прошел нормально. Обратите внимание на lsn=41/DCCA8F38 — это соответствует той точке, где recovery остановился.

Выполняем на `pg-master` тот же запрос и видим данные, которые были на репликах.

```sql
select user_id, username from users where user_id >= 2773780;

user_id |   username   
---------+--------------
 2773780 | user_5290802
 2773781 | user_3240022
 2773782 | user_4085763
 2773783 | user_4376007
 2773784 | user_2188319
 2773785 | user_4530843
 2773786 | user_122004
 2773787 | user_6810711
 2773788 | user_9264952
(9 rows)
```

Таким образом мы видим, что потери данных при репликации небыло.

Для интереса можно запустить реплики и ознакомиться с их логами:

**pg-slave01**

```
2025-09-19 14:02:06.512 UTC [31889] LOG:  database system was shut down in recovery at 2025-09-19 12:51:52 UTC
2025-09-19 14:02:06.513 UTC [31889] LOG:  entering standby mode
2025-09-19 14:02:06.515 UTC [31889] LOG:  redo starts at 41/D98D3678
2025-09-19 14:02:06.597 UTC [31889] LOG:  consistent recovery state reached at 41/DCCA8F38
2025-09-19 14:02:06.597 UTC [31889] LOG:  record with incorrect prev-link 1CFEC0C/A09102B0 at 41/DCCA8F38
2025-09-19 14:02:06.597 UTC [31885] LOG:  database system is ready to accept read-only connections
2025-09-19 14:02:06.605 UTC [31891] LOG:  started streaming WAL from primary at 41/DC000000 on timeline 1
```

**pg-slave02**

```
2025-09-19 14:02:37.293 UTC [31885] LOG:  database system was shut down in recovery at 2025-09-19 12:51:57 UTC
2025-09-19 14:02:37.293 UTC [31885] LOG:  entering standby mode
2025-09-19 14:02:37.296 UTC [31885] LOG:  redo starts at 41/D98D3678
2025-09-19 14:02:37.384 UTC [31885] LOG:  consistent recovery state reached at 41/DCCA8F38
2025-09-19 14:02:37.384 UTC [31885] LOG:  record with incorrect prev-link 2790010/80000001 at 41/DCCA8F38
2025-09-19 14:02:37.384 UTC [31881] LOG:  database system is ready to accept read-only connections
2025-09-19 14:02:37.391 UTC [31888] LOG:  started streaming WAL from primary at 41/DC000000 on timeline 1
```
